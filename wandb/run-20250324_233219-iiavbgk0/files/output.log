Estimating norm scaling factor:   0%|          | 0/1000 [00:00<?, ?it/s]
Traceback (most recent call last):0%|          | 0/1000 [00:00<?, ?it/s]
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/train_SAE.py", line 87, in <module>
    main()
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/train_SAE.py", line 80, in main
    sparse_autoencoder = SAETrainingRunner(cfg).run()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 113, in run
    sae = self.run_trainer_with_interruption_handling(trainer)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 152, in run_trainer_with_interruption_handling
    sae = trainer.fit()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/sae_trainer.py", line 177, in fit
    self.activations_store.set_norm_scaling_factor_if_needed()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 421, in set_norm_scaling_factor_if_needed
    self.estimated_norm_scaling_factor = self.estimate_norm_scaling_factor()
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 448, in estimate_norm_scaling_factor
    acts = self.next_batch()[0]
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 781, in next_batch
    return next(self.dataloader)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 486, in dataloader
    self._dataloader = self.get_data_loader()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 733, in get_data_loader
    self.get_buffer(self.half_buffer_size, raise_on_epoch_end=True),
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 687, in get_buffer
    refill_activations = self.get_activations(refill_batch_tokens)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 565, in get_activations
    stacked_activations[:, :, 0] = layerwise_activations
RuntimeError: The expanded size of the tensor (2048) must match the existing size (1280) at non-singleton dimension 2.  Target sizes: [4, 512, 2048].  Tensor sizes: [4, 512, 1280]
Traceback (most recent call last):
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/train_SAE.py", line 87, in <module>
    main()
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/train_SAE.py", line 80, in main
    sparse_autoencoder = SAETrainingRunner(cfg).run()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 113, in run
    sae = self.run_trainer_with_interruption_handling(trainer)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 152, in run_trainer_with_interruption_handling
    sae = trainer.fit()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/sae_trainer.py", line 177, in fit
    self.activations_store.set_norm_scaling_factor_if_needed()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 421, in set_norm_scaling_factor_if_needed
    self.estimated_norm_scaling_factor = self.estimate_norm_scaling_factor()
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 448, in estimate_norm_scaling_factor
    acts = self.next_batch()[0]
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 781, in next_batch
    return next(self.dataloader)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 486, in dataloader
    self._dataloader = self.get_data_loader()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 733, in get_data_loader
    self.get_buffer(self.half_buffer_size, raise_on_epoch_end=True),
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 687, in get_buffer
    refill_activations = self.get_activations(refill_batch_tokens)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 565, in get_activations
    stacked_activations[:, :, 0] = layerwise_activations
RuntimeError: The expanded size of the tensor (2048) must match the existing size (1280) at non-singleton dimension 2.  Target sizes: [4, 512, 2048].  Tensor sizes: [4, 512, 1280]
