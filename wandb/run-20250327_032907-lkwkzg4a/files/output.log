Training SAE:   0%|          | 0/4096000 [00:00<?, ?it//data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:   2%|▎         | 25/1000 [00:00<00:27, 36.05it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:   6%|▌         | 57/1000 [00:01<00:22, 41.12it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:   9%|▉         | 93/1000 [00:03<00:40, 22.21it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  12%|█▎        | 125/1000 [00:05<00:44, 19.55it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  16%|█▌        | 157/1000 [00:07<00:43, 19.32it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  19%|█▉        | 189/1000 [00:09<00:39, 20.34it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  22%|██▏       | 217/1000 [00:11<00:30, 25.84it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  25%|██▍       | 249/1000 [00:12<00:23, 32.10it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  28%|██▊       | 281/1000 [00:13<00:18, 39.92it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  31%|███▏      | 314/1000 [00:13<00:17, 39.78it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  34%|███▍      | 345/1000 [00:14<00:16, 39.79it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  38%|███▊      | 381/1000 [00:17<00:30, 20.31it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  41%|████▏     | 413/1000 [00:19<00:28, 20.67it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  44%|████▍     | 445/1000 [00:20<00:27, 19.83it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  48%|████▊     | 477/1000 [00:22<00:25, 20.68it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  50%|█████     | 505/1000 [00:24<00:22, 21.57it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  54%|█████▎    | 537/1000 [00:25<00:12, 37.32it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  57%|█████▋    | 573/1000 [00:26<00:11, 37.41it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  60%|██████    | 605/1000 [00:27<00:10, 36.98it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  63%|██████▎   | 633/1000 [00:28<00:09, 37.65it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  67%|██████▋   | 669/1000 [00:29<00:14, 23.27it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  70%|███████   | 701/1000 [00:31<00:14, 20.01it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  73%|███████▎  | 733/1000 [00:33<00:13, 19.80it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  76%|███████▋  | 765/1000 [00:35<00:11, 20.62it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  80%|███████▉  | 797/1000 [00:37<00:10, 19.81it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  83%|████████▎ | 829/1000 [00:38<00:04, 34.90it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  86%|████████▌ | 857/1000 [00:39<00:03, 40.04it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  89%|████████▉ | 889/1000 [00:40<00:02, 42.58it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  92%|█████████▏| 921/1000 [00:40<00:01, 43.28it/s]
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  95%|█████████▌| 953/1000 [00:41<00:01, 43.12it/s]
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(scaling factor:  99%|█████████▉| 991/1000 [00:42<00:00, 31.70it/s]
Estimating norm scaling factor: 100%|██████████| 1000/1000 [00:43<00:00, 22.87it/s]
Estimating norm scaling factor: 100%|█████████▉| 998/1000 [00:4/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
100| auxiliary_reconstruction_loss: 21693.54688 | l1_lo/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.35816677771008476, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 6.621574878692627, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.08325071632862091, 'mse': 25.6020565032959, 'cossim': 0.22685544192790985}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 0.10632746666669846, 'l2_ratio': 0.00033458034158684313, 'relative_reconstruction_bias': 0.012150577269494534}, 'sparsity': {'l0': 142.7685546875, 'l1': 112.4975814819336}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
200| auxiliary_reconstruction_loss: 5105.37061 | l1_loss: 30.43/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
300| auxiliary_reconstruction_loss: 2955.80054 | l1_loss: 104.1/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.4636639401154745, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 6.070210933685303, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.08404211699962616, 'mse': 24.69274139404297, 'cossim': 0.2881642282009125}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 0.3967474102973938, 'l2_ratio': 0.0006887157796882093, 'relative_reconstruction_bias': 0.02940150909125805}, 'sparsity': {'l0': 114.54219055175781, 'l1': 476.42486572265625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
400| auxiliary_reconstruction_loss: 3073.50879 | l1_loss: 199.2/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.4334863953945726, 'ce_loss_with_ablation': 8.657638549804688, 'ce_loss_with_sae': 6.460413932800293, 'ce_loss_without_sae': 3.5889105796813965}, 'reconstruction_quality': {'explained_variance': 0.06385985761880875, 'mse': 22.235294342041016, 'cossim': 0.31529608368873596}, 'shrinkage': {'l2_norm_in': 44.62173843383789, 'l2_norm_out': 0.5144885182380676, 'l2_ratio': 0.0008782055228948593, 'relative_reconstruction_bias': 0.03754506632685661}, 'sparsity': {'l0': 88.51094055175781, 'l1': 619.905029296875}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
500| auxiliary_reconstruction_loss: 1469.37500 | l1_loss: 103.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
600| auxiliary_reconstruction_loss: 1094.11475 | l1_loss: 146.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.5725327048152421, 'ce_loss_with_ablation': 8.144485473632812, 'ce_loss_with_sae': 5.371108055114746, 'ce_loss_without_sae': 3.3004348278045654}, 'reconstruction_quality': {'explained_variance': 0.058402158319950104, 'mse': 21.183027267456055, 'cossim': 0.31563836336135864}, 'shrinkage': {'l2_norm_in': 44.21681594848633, 'l2_norm_out': 0.6333475708961487, 'l2_ratio': 0.003385536838322878, 'relative_reconstruction_bias': 0.041170667856931686}, 'sparsity': {'l0': 103.14570617675781, 'l1': 716.5712280273438}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
700| auxiliary_reconstruction_loss: 927.08862 | l1_loss: 135.37/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
700| auxiliary_reconstruction_loss: 927.08862 | l1_loss/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.45095883799514297, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 6.197534561157227, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.08853896707296371, 'mse': 23.201765060424805, 'cossim': 0.4143697917461395}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 0.9595123529434204, 'l2_ratio': 0.011922954581677914, 'relative_reconstruction_bias': 0.04145868495106697}, 'sparsity': {'l0': 161.9619140625, 'l1': 857.1558837890625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
800| auxiliary_reconstruction_loss: 904.74994 | l1_loss: 187.70/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
900| auxiliary_reconstruction_loss: 809.75134 | l1_loss: 147.08/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.4985371898331527, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 5.959304332733154, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.09328364580869675, 'mse': 23.193288803100586, 'cossim': 0.5039986968040466}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.0441423654556274, 'l2_ratio': 0.014698132872581482, 'relative_reconstruction_bias': 0.04133929684758186}, 'sparsity': {'l0': 208.2423858642578, 'l1': 894.1875}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
1000| auxiliary_reconstruction_loss: 832.05139 | l1_loss: 144.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.6284417851469543, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 5.386826992034912, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.10536707937717438, 'mse': 24.055570602416992, 'cossim': 0.5738636255264282}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.1383217573165894, 'l2_ratio': 0.016924476251006126, 'relative_reconstruction_bias': 0.04125158116221428}, 'sparsity': {'l0': 243.5222625732422, 'l1': 940.3207397460938}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
1100| auxiliary_reconstruction_loss: 735.09521 | l1_loss: 175.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
1200| auxiliary_reconstruction_loss: 662.87488 | l1_loss: 165.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.7092388338259007, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 4.978268146514893, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.10932788997888565, 'mse': 24.044513702392578, 'cossim': 0.6286466717720032}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.19720458984375, 'l2_ratio': 0.018842017278075218, 'relative_reconstruction_bias': 0.04127351567149162}, 'sparsity': {'l0': 265.8505859375, 'l1': 949.4610595703125}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
1300| auxiliary_reconstruction_loss: 667.45508 | l1_loss: 186.2/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.8332791763824906, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 4.138476371765137, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.10977935791015625, 'mse': 23.790006637573242, 'cossim': 0.6666620373725891}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.246305227279663, 'l2_ratio': 0.0204748697578907, 'relative_reconstruction_bias': 0.041295375674963}, 'sparsity': {'l0': 291.2548828125, 'l1': 950.4177856445312}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
1400| auxiliary_reconstruction_loss: 638.48401 | l1_loss: 157.2/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
1500| auxiliary_reconstruction_loss: 602.36243 | l1_loss: 141.2/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.8671661301532262, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.961371660232544, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.11278732120990753, 'mse': 23.78359031677246, 'cossim': 0.698502242565155}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.2916072607040405, 'l2_ratio': 0.021942541003227234, 'relative_reconstruction_bias': 0.041279640048742294}, 'sparsity': {'l0': 298.70587158203125, 'l1': 951.6968994140625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
1600| auxiliary_reconstruction_loss: 509.79764 | l1_loss: 201.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.8811064231784835, 'ce_loss_with_ablation': 8.657638549804688, 'ce_loss_with_sae': 4.191549777984619, 'ce_loss_without_sae': 3.5889105796813965}, 'reconstruction_quality': {'explained_variance': 0.09586962312459946, 'mse': 21.90958595275879, 'cossim': 0.7338939309120178}, 'shrinkage': {'l2_norm_in': 44.62173843383789, 'l2_norm_out': 1.271422266960144, 'l2_ratio': 0.0232845526188612, 'relative_reconstruction_bias': 0.041370488703250885}, 'sparsity': {'l0': 272.17559814453125, 'l1': 884.6463012695312}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
1600| auxiliary_reconstruction_loss: 509.79764 | l1_loss: 201.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
1700| auxiliary_reconstruction_loss: 570.57642 | l1_loss: 218.4/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
1800| auxiliary_reconstruction_loss: 552.40393 | l1_loss: 192.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9166545793385883, 'ce_loss_with_ablation': 8.144485473632812, 'ce_loss_with_sae': 3.7041642665863037, 'ce_loss_without_sae': 3.3004348278045654}, 'reconstruction_quality': {'explained_variance': 0.08765576034784317, 'mse': 21.105016708374023, 'cossim': 0.7207379937171936}, 'shrinkage': {'l2_norm_in': 44.21681594848633, 'l2_norm_out': 1.2332127094268799, 'l2_ratio': 0.022855842486023903, 'relative_reconstruction_bias': 0.04126742482185364}, 'sparsity': {'l0': 298.3072204589844, 'l1': 852.1795043945312}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
1900| auxiliary_reconstruction_loss: 483.48795 | l1_loss: 211.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.8699464101321448, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 4.099616050720215, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.11613553017377853, 'mse': 23.13559913635254, 'cossim': 0.7768653035163879}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.3784480094909668, 'l2_ratio': 0.02564532868564129, 'relative_reconstruction_bias': 0.04137982800602913}, 'sparsity': {'l0': 266.42462158203125, 'l1': 923.0075073242188}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
2000| auxiliary_reconstruction_loss: 497.08307 | l1_loss: 231.6/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
2100| auxiliary_reconstruction_loss: 475.01013 | l1_loss: 200.6/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.8830123271076089, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 4.034193515777588, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.11773023754358292, 'mse': 23.1339168548584, 'cossim': 0.7902361750602722}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.4007937908172607, 'l2_ratio': 0.026379069313406944, 'relative_reconstruction_bias': 0.04133530333638191}, 'sparsity': {'l0': 260.3193359375, 'l1': 920.1039428710938}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
2200| auxiliary_reconstruction_loss: 466.86948 | l1_loss: 227.1/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
2200| auxiliary_reconstruction_loss: 466.86948 | l1_loss: 227.1/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9079423241412833, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.9735028743743896, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.1256377100944519, 'mse': 24.006349563598633, 'cossim': 0.7924918532371521}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.4393064975738525, 'l2_ratio': 0.026628151535987854, 'relative_reconstruction_bias': 0.04125228151679039}, 'sparsity': {'l0': 259.0287170410156, 'l1': 944.9278564453125}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
2300| auxiliary_reconstruction_loss: 434.95987 | l1_loss: 207.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
2400| auxiliary_reconstruction_loss: 440.22198 | l1_loss: 187.1/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9144377444929717, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.9406580924987793, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.12679098546504974, 'mse': 24.00347900390625, 'cossim': 0.8017884492874146}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.456374168395996, 'l2_ratio': 0.027164150029420853, 'relative_reconstruction_bias': 0.041255418211221695}, 'sparsity': {'l0': 250.47715759277344, 'l1': 942.1267700195312}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
2500| auxiliary_reconstruction_loss: 458.05020 | l1_loss: 224.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
2500| auxiliary_reconstruction_loss: 458.05020 | l1_loss: 224.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9399683087178853, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.5808827877044678, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.12422257661819458, 'mse': 23.75241470336914, 'cossim': 0.802868664264679}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.4622061252593994, 'l2_ratio': 0.027286341413855553, 'relative_reconstruction_bias': 0.041359491646289825}, 'sparsity': {'l0': 254.4267578125, 'l1': 938.6217041015625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
2600| auxiliary_reconstruction_loss: 450.66937 | l1_loss: 190.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
2700| auxiliary_reconstruction_loss: 459.37830 | l1_loss: 229.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9443903990058782, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.5577714443206787, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.12511935830116272, 'mse': 23.746374130249023, 'cossim': 0.8101009726524353}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.4766699075698853, 'l2_ratio': 0.02769424393773079, 'relative_reconstruction_bias': 0.0414440743625164}, 'sparsity': {'l0': 246.4453125, 'l1': 938.1140747070312}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
2800| auxiliary_reconstruction_loss: 369.58612 | l1_loss: 207.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9499086679423773, 'ce_loss_with_ablation': 8.657638549804688, 'ce_loss_with_sae': 3.8428099155426025, 'ce_loss_without_sae': 3.5889105796813965}, 'reconstruction_quality': {'explained_variance': 0.10758435726165771, 'mse': 21.879819869995117, 'cossim': 0.8314691781997681}, 'shrinkage': {'l2_norm_in': 44.62173843383789, 'l2_norm_out': 1.4389902353286743, 'l2_ratio': 0.028536835685372353, 'relative_reconstruction_bias': 0.041441723704338074}, 'sparsity': {'l0': 207.77207946777344, 'l1': 869.087890625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
2900| auxiliary_reconstruction_loss: 423.16516 | l1_loss: 247.1/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3000| auxiliary_reconstruction_loss: 406.99509 | l1_loss: 198.5/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.961103577073094, 'ce_loss_with_ablation': 8.144485473632812, 'ce_loss_with_sae': 3.4888510704040527, 'ce_loss_without_sae': 3.3004348278045654}, 'reconstruction_quality': {'explained_variance': 0.09738332033157349, 'mse': 21.08591651916504, 'cossim': 0.8045634627342224}, 'shrinkage': {'l2_norm_in': 44.21681594848633, 'l2_norm_out': 1.3703696727752686, 'l2_ratio': 0.027217242866754532, 'relative_reconstruction_bias': 0.041180938482284546}, 'sparsity': {'l0': 234.49082946777344, 'l1': 834.7316284179688}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3000| auxiliary_reconstruction_loss: 406.99509 | l1_loss: 198.5/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3100| auxiliary_reconstruction_loss: 370.41220 | l1_loss: 256.9/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3100| auxiliary_reconstruction_loss: 370.41220 | l1_loss: 256.9/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9258325104500386, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 3.8197879791259766, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.1246427446603775, 'mse': 23.11604118347168, 'cossim': 0.8431650996208191}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.5007683038711548, 'l2_ratio': 0.02950054407119751, 'relative_reconstruction_bias': 0.041378673166036606}, 'sparsity': {'l0': 206.66172790527344, 'l1': 903.5888671875}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
3200| auxiliary_reconstruction_loss: 322.70096 | l1_loss: 251.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3300| auxiliary_reconstruction_loss: 365.38922 | l1_loss: 232.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9283267777255166, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 3.8072988986968994, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.12516465783119202, 'mse': 23.115190505981445, 'cossim': 0.8464849591255188}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.5085691213607788, 'l2_ratio': 0.029745830222964287, 'relative_reconstruction_bias': 0.04137356951832771}, 'sparsity': {'l0': 203.1960906982422, 'l1': 901.5}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3400| auxiliary_reconstruction_loss: 354.05646 | l1_loss: 231.1/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9421802397224605, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.80037522315979, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.13214917480945587, 'mse': 23.987571716308594, 'cossim': 0.8425431251525879}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.5364971160888672, 'l2_ratio': 0.029605228453874588, 'relative_reconstruction_bias': 0.04132631793618202}, 'sparsity': {'l0': 202.7521514892578, 'l1': 926.9651489257812}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
3500| auxiliary_reconstruction_loss: 348.25513 | l1_loss: 226.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3600| auxiliary_reconstruction_loss: 372.20697 | l1_loss: 203.1/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9442393710992575, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.7899630069732666, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.13261139392852783, 'mse': 23.987934112548828, 'cossim': 0.8456980586051941}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.542991042137146, 'l2_ratio': 0.0298187043517828, 'relative_reconstruction_bias': 0.04129603132605553}, 'sparsity': {'l0': 198.65977478027344, 'l1': 924.4808959960938}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3700| auxiliary_reconstruction_loss: 371.29449 | l1_los/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9605323332506875, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.4734082221984863, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.12943175435066223, 'mse': 23.739675521850586, 'cossim': 0.8426805734634399}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.5394006967544556, 'l2_ratio': 0.02964578941464424, 'relative_reconstruction_bias': 0.04136550799012184}, 'sparsity': {'l0': 203.17442321777344, 'l1': 921.1658325195312}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
3800| auxiliary_reconstruction_loss: 353.01758 | l1_loss: 218.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3900| auxiliary_reconstruction_loss: 377.01923 | l1_loss: 248.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.961735844701313, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.467118263244629, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.12985621392726898, 'mse': 23.741514205932617, 'cossim': 0.8455604910850525}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.54498291015625, 'l2_ratio': 0.029842466115951538, 'relative_reconstruction_bias': 0.04130720719695091}, 'sparsity': {'l0': 199.4005889892578, 'l1': 918.6140747070312}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
3900| auxiliary_reconstruction_loss: 377.01923 | l1_loss: 248.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
4000| auxiliary_reconstruction_loss: 332.83618 | l1_loss: 235.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9681914954365016, 'ce_loss_with_ablation': 8.657638549804688, 'ce_loss_with_sae': 3.7501392364501953, 'ce_loss_without_sae': 3.5889105796813965}, 'reconstruction_quality': {'explained_variance': 0.11211355030536652, 'mse': 21.874460220336914, 'cossim': 0.8615531325340271}, 'shrinkage': {'l2_norm_in': 44.62173843383789, 'l2_norm_out': 1.5027577877044678, 'l2_ratio': 0.030560864135622978, 'relative_reconstruction_bias': 0.04134143888950348}, 'sparsity': {'l0': 168.6277313232422, 'l1': 850.2701416015625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
4100| auxiliary_reconstruction_loss: 335.83636 | l1_loss: 251.6/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
4200| auxiliary_reconstruction_loss: 332.23187 | l1_loss: 218.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9715379722652792, 'ce_loss_with_ablation': 8.144485473632812, 'ce_loss_with_sae': 3.4383063316345215, 'ce_loss_without_sae': 3.3004348278045654}, 'reconstruction_quality': {'explained_variance': 0.10147092491388321, 'mse': 21.073232650756836, 'cossim': 0.8336274027824402}, 'shrinkage': {'l2_norm_in': 44.21681594848633, 'l2_norm_out': 1.4303416013717651, 'l2_ratio': 0.029031598940491676, 'relative_reconstruction_bias': 0.04126227647066116}, 'sparsity': {'l0': 194.43496704101562, 'l1': 820.9781494140625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
4200| auxiliary_reconstruction_loss: 332.23187 | l1_loss: 218.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
4300| auxiliary_reconstruction_loss: 306.37064 | l1_loss: 225.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.944701433116849, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 3.725309133529663, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.12814302742481232, 'mse': 23.10753059387207, 'cossim': 0.8666641116142273}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.551658034324646, 'l2_ratio': 0.03106778860092163, 'relative_reconstruction_bias': 0.041390009224414825}, 'sparsity': {'l0': 175.1824188232422, 'l1': 887.2136840820312}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
4400| auxiliary_reconstruction_loss: 311.81720 | l1_loss: 254.6/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
4500| auxiliary_reconstruction_loss: 318.04321 | l1_loss: 243.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9458343122382847, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 3.7196366786956787, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.12841510772705078, 'mse': 23.104398727416992, 'cossim': 0.8683032393455505}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.5565279722213745, 'l2_ratio': 0.031191755086183548, 'relative_reconstruction_bias': 0.04144575074315071}, 'sparsity': {'l0': 172.8302764892578, 'l1': 886.6310424804688}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
4600| auxiliary_reconstruction_loss: 350.61957 | l1_loss: 277.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9544993826425013, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.73808217048645, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.13512957096099854, 'mse': 23.979373931884766, 'cossim': 0.8631078600883484}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.5807780027389526, 'l2_ratio': 0.030947744846343994, 'relative_reconstruction_bias': 0.04135243967175484}, 'sparsity': {'l0': 174.5701141357422, 'l1': 911.2514038085938}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
4700| auxiliary_reconstruction_loss: 296.67200 | l1_loss: 206.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
4800| auxiliary_reconstruction_loss: 315.07083 | l1_loss: 208.4/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.955448463414702, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.733283042907715, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.13537488877773285, 'mse': 23.97882080078125, 'cossim': 0.8646659255027771}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.5844134092330933, 'l2_ratio': 0.03105979971587658, 'relative_reconstruction_bias': 0.041352611035108566}, 'sparsity': {'l0': 171.76699829101562, 'l1': 909.69775390625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
4900| auxiliary_reconstruction_loss: 337.85608 | l1_loss: 232.2/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9682688015590633, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.4329748153686523, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.1319885402917862, 'mse': 23.734846115112305, 'cossim': 0.8601101040840149}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.5771995782852173, 'l2_ratio': 0.030800629407167435, 'relative_reconstruction_bias': 0.041345324367284775}, 'sparsity': {'l0': 178.8839874267578, 'l1': 906.95458984375}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
5000| auxiliary_reconstruction_loss: 324.90286 | l1_loss: 207.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
5100| auxiliary_reconstruction_loss: 351.86194 | l1_loss: 222.1/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9689778523693533, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.4292690753936768, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.1322038620710373, 'mse': 23.736278533935547, 'cossim': 0.861417293548584}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.5798892974853516, 'l2_ratio': 0.030901288613677025, 'relative_reconstruction_bias': 0.0413048230111599}, 'sparsity': {'l0': 176.5124969482422, 'l1': 904.7247924804688}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
5200| auxiliary_reconstruction_loss: 262.28296 | l1_loss: 221.2/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9742662038084485, 'ce_loss_with_ablation': 8.657638549804688, 'ce_loss_with_sae': 3.719348192214966, 'ce_loss_without_sae': 3.5889105796813965}, 'reconstruction_quality': {'explained_variance': 0.1143164187669754, 'mse': 21.871421813964844, 'cossim': 0.8749485015869141}, 'shrinkage': {'l2_norm_in': 44.62173843383789, 'l2_norm_out': 1.5339874029159546, 'l2_ratio': 0.03154144808650017, 'relative_reconstruction_bias': 0.041304122656583786}, 'sparsity': {'l0': 149.25527954101562, 'l1': 836.4515991210938}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
5300| auxiliary_reconstruction_loss: 288.43973 | l1_loss: 285.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
5400| auxiliary_reconstruction_loss: 324.64301 | l1_loss: 241.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9758355649567925, 'ce_loss_with_ablation': 8.144485473632812, 'ce_loss_with_sae': 3.4174885749816895, 'ce_loss_without_sae': 3.3004348278045654}, 'reconstruction_quality': {'explained_variance': 0.10356780141592026, 'mse': 21.069534301757812, 'cossim': 0.8472476005554199}, 'shrinkage': {'l2_norm_in': 44.21681594848633, 'l2_norm_out': 1.4604761600494385, 'l2_ratio': 0.02996346913278103, 'relative_reconstruction_bias': 0.04123936966061592}, 'sparsity': {'l0': 174.6369171142578, 'l1': 808.5009765625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
5500| auxiliary_reconstruction_loss: 282.42514 | l1_loss: 225.2/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9531509819507862, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 3.6830012798309326, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.12986154854297638, 'mse': 23.1040096282959, 'cossim': 0.8771206140518188}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.576769232749939, 'l2_ratio': 0.03184295818209648, 'relative_reconstruction_bias': 0.04138554260134697}, 'sparsity': {'l0': 159.73281860351562, 'l1': 874.6229858398438}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
5600| auxiliary_reconstruction_loss: 264.93314 | l1_loss: 237.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
5700| auxiliary_reconstruction_loss: 298.03186 | l1_loss: 216.5/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9540635896021581, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 3.678431749343872, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.12999917566776276, 'mse': 23.103239059448242, 'cossim': 0.8778058290481567}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.579062581062317, 'l2_ratio': 0.031909871846437454, 'relative_reconstruction_bias': 0.04139631614089012}, 'sparsity': {'l0': 158.7121124267578, 'l1': 873.4435424804688}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
5800| auxiliary_reconstruction_loss: 265.08643 | l1_loss: 202.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9602463451384635, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.709022045135498, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.136613667011261, 'mse': 23.975791931152344, 'cossim': 0.8724151849746704}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.6029999256134033, 'l2_ratio': 0.03162524476647377, 'relative_reconstruction_bias': 0.04135715961456299}, 'sparsity': {'l0': 160.5173797607422, 'l1': 899.2201538085938}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
5900| auxiliary_reconstruction_loss: 286.42999 | l1_loss: 191.5/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
6000| auxiliary_reconstruction_loss: 329.66199 | l1_loss: 218.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9606050145921935, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.7072083950042725, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.1367470771074295, 'mse': 23.97601890563965, 'cossim': 0.8732447028160095}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.6047852039337158, 'l2_ratio': 0.031685970723629, 'relative_reconstruction_bias': 0.041346605867147446}, 'sparsity': {'l0': 158.99258422851562, 'l1': 897.9541015625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
6100| auxiliary_reconstruction_loss: 290.86407 | l1_los/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9719641866158961, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.413661479949951, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.13327686488628387, 'mse': 23.729711532592773, 'cossim': 0.8682786822319031}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.5971750020980835, 'l2_ratio': 0.0313861221075058, 'relative_reconstruction_bias': 0.04138903692364693}, 'sparsity': {'l0': 165.99278259277344, 'l1': 896.5166015625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
6200| auxiliary_reconstruction_loss: 310.35297 | l1_loss: 258.2/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
6300| auxiliary_reconstruction_loss: 338.33829 | l1_loss: 203.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9722187843494243, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.4123308658599854, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.13337184488773346, 'mse': 23.728647232055664, 'cossim': 0.8687383532524109}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.5990289449691772, 'l2_ratio': 0.031433746218681335, 'relative_reconstruction_bias': 0.04140854626893997}, 'sparsity': {'l0': 165.80137634277344, 'l1': 896.1337890625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
6400| auxiliary_reconstruction_loss: 278.96542 | l1_loss: 234.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
6400| auxiliary_reconstruction_loss: 278.96542 | l1_loss: 234.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9767533878280806, 'ce_loss_with_ablation': 8.657638549804688, 'ce_loss_with_sae': 3.7067413330078125, 'ce_loss_without_sae': 3.5889105796813965}, 'reconstruction_quality': {'explained_variance': 0.11536865681409836, 'mse': 21.867902755737305, 'cossim': 0.8809278607368469}, 'shrinkage': {'l2_norm_in': 44.62173843383789, 'l2_norm_out': 1.5496810674667358, 'l2_ratio': 0.03201630339026451, 'relative_reconstruction_bias': 0.0413362942636013}, 'sparsity': {'l0': 139.4443359375, 'l1': 827.9547119140625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
6500| auxiliary_reconstruction_loss: 311.34888 | l1_loss: 214.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
6600| auxiliary_reconstruction_loss: 308.07901 | l1_loss: 270.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9777077021734205, 'ce_loss_with_ablation': 8.144485473632812, 'ce_loss_with_sae': 3.4084198474884033, 'ce_loss_without_sae': 3.3004348278045654}, 'reconstruction_quality': {'explained_variance': 0.10457298904657364, 'mse': 21.06638526916504, 'cossim': 0.8532950282096863}, 'shrinkage': {'l2_norm_in': 44.21681594848633, 'l2_norm_out': 1.475580096244812, 'l2_ratio': 0.03041933849453926, 'relative_reconstruction_bias': 0.04126226529479027}, 'sparsity': {'l0': 165.5447235107422, 'l1': 801.4625244140625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
6700| auxiliary_reconstruction_loss: 269.02594 | l1_loss: 217.0/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9569098817324099, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 3.664180040359497, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.13070671260356903, 'mse': 23.103256225585938, 'cossim': 0.8820085525512695}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.5888738632202148, 'l2_ratio': 0.032227613031864166, 'relative_reconstruction_bias': 0.04136389121413231}, 'sparsity': {'l0': 152.0349578857422, 'l1': 866.6275634765625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
6800| auxiliary_reconstruction_loss: 264.83148 | l1_loss: 283.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
6900| auxiliary_reconstruction_loss: 264.70850 | l1_loss: 197.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9571760549960626, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 3.6628472805023193, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.13077209889888763, 'mse': 23.100627899169922, 'cossim': 0.8823164105415344}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.590733528137207, 'l2_ratio': 0.032259728759527206, 'relative_reconstruction_bias': 0.041417982429265976}, 'sparsity': {'l0': 152.3035125732422, 'l1': 866.8837890625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7000| auxiliary_reconstruction_loss: 329.97522 | l1_loss: 246.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7000| auxiliary_reconstruction_loss: 329.97522 | l1_loss: 246.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9627750897345521, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.696235179901123, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.1373426914215088, 'mse': 23.97272300720215, 'cossim': 0.8768033981323242}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.6143516302108765, 'l2_ratio': 0.03195934370160103, 'relative_reconstruction_bias': 0.04138807952404022}, 'sparsity': {'l0': 154.02989196777344, 'l1': 892.7604370117188}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
7100| auxiliary_reconstruction_loss: 294.39703 | l1_loss: 224.7/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7200| auxiliary_reconstruction_loss: 298.28519 | l1_loss: 244.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9630312552586897, 'ce_loss_with_ablation': 8.56460952758789, 'ce_loss_with_sae': 3.6949398517608643, 'ce_loss_without_sae': 3.5080034732818604}, 'reconstruction_quality': {'explained_variance': 0.13739578425884247, 'mse': 23.97328758239746, 'cossim': 0.8770999908447266}, 'shrinkage': {'l2_norm_in': 46.43986129760742, 'l2_norm_out': 1.6149696111679077, 'l2_ratio': 0.03198431059718132, 'relative_reconstruction_bias': 0.041374653577804565}, 'sparsity': {'l0': 153.35781860351562, 'l1': 892.1959228515625}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7300| auxiliary_reconstruction_loss: 302.60104 | l1_loss: 233.6/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7300| auxiliary_reconstruction_loss: 302.60104 | l1_loss: 233.6/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9736066407993667, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.4050774574279785, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.13387466967105865, 'mse': 23.728471755981445, 'cossim': 0.8718973398208618}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.606177568435669, 'l2_ratio': 0.031660180538892746, 'relative_reconstruction_bias': 0.04138846695423126}, 'sparsity': {'l0': 160.517578125, 'l1': 890.9060668945312}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
7400| auxiliary_reconstruction_loss: 287.74371 | l1_loss: 235.2/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7500| auxiliary_reconstruction_loss: 325.44235 | l1_loss: 255.6/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9737101039170233, 'ce_loss_with_ablation': 8.493475914001465, 'ce_loss_with_sae': 3.404536724090576, 'ce_loss_without_sae': 3.267136812210083}, 'reconstruction_quality': {'explained_variance': 0.13392996788024902, 'mse': 23.728334426879883, 'cossim': 0.872180163860321}, 'shrinkage': {'l2_norm_in': 46.52678298950195, 'l2_norm_out': 1.607115387916565, 'l2_ratio': 0.03168722987174988, 'relative_reconstruction_bias': 0.04138939455151558}, 'sparsity': {'l0': 160.58828735351562, 'l1': 890.6146850585938}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7600| auxiliary_reconstruction_loss: 259.65302 | l1_loss: 247.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9778393818263269, 'ce_loss_with_ablation': 8.657638549804688, 'ce_loss_with_sae': 3.7012367248535156, 'ce_loss_without_sae': 3.5889105796813965}, 'reconstruction_quality': {'explained_variance': 0.11589781194925308, 'mse': 21.867115020751953, 'cossim': 0.883802056312561}, 'shrinkage': {'l2_norm_in': 44.62173843383789, 'l2_norm_out': 1.5573205947875977, 'l2_ratio': 0.032256629317998886, 'relative_reconstruction_bias': 0.04133104160428047}, 'sparsity': {'l0': 135.7236328125, 'l1': 823.0050048828125}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
7600| auxiliary_reconstruction_loss: 259.65302 | l1_loss: 247.8/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7700| auxiliary_reconstruction_loss: 309.77939 | l1_loss: 261.3/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7800| auxiliary_reconstruction_loss: 289.61798 | l1_los/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.978569179621764, 'ce_loss_with_ablation': 8.144485473632812, 'ce_loss_with_sae': 3.4042468070983887, 'ce_loss_without_sae': 3.3004348278045654}, 'reconstruction_quality': {'explained_variance': 0.10508228838443756, 'mse': 21.064924240112305, 'cossim': 0.8562227487564087}, 'shrinkage': {'l2_norm_in': 44.21681594848633, 'l2_norm_out': 1.4832342863082886, 'l2_ratio': 0.030651668086647987, 'relative_reconstruction_bias': 0.04127270728349686}, 'sparsity': {'l0': 161.4972686767578, 'l1': 797.126220703125}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                               /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
7900| auxiliary_reconstruction_loss: 269.95831 | l1_loss: 247.5/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
                                                       /data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py:741: UserWarning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.
  warnings.warn(                                               
sae_trainer.py:348 {'model_performance_preservation': {'ce_loss_score': 0.9586072957758256, 'ce_loss_with_ablation': 8.455536842346191, 'ce_loss_with_sae': 3.6556808948516846, 'ce_loss_without_sae': 3.448422908782959}, 'reconstruction_quality': {'explained_variance': 0.1311298906803131, 'mse': 23.100770950317383, 'cossim': 0.8843545913696289}, 'shrinkage': {'l2_norm_in': 45.55447006225586, 'l2_norm_out': 1.595664381980896, 'l2_ratio': 0.03242183476686478, 'relative_reconstruction_bias': 0.04139929637312889}, 'sparsity': {'l0': 148.31582641601562, 'l1': 862.7948608398438}, 'token_stats': {'total_tokens_eval_reconstruction': 5120, 'total_tokens_eval_sparsity_variance': 5120}}
8000| auxiliary_reconstruction_loss: 245.51534 | l1_loss: 205.11539 | mse_loss: 7.19415: 100%|██████████| 4096000/4096000 [17:48<00:00, 3832.54it/s]
                                                               
