Estimating norm scaling factor:  34%|███▎      | 336/1000 [00:07<00:14, 44.97it/s]
interrupted, saving progressor:  33%|███▎      | 329/1000 [00:07<00:11, 56.58it/s]
Traceback (most recent call last):                             
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 782, in next_batch
    return next(self.dataloader)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 763, in _next_data
    index = self._next_index()  # may raise StopIteration
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 698, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/train_SAE.py", line 94, in <module>
    main()
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/train_SAE.py", line 89, in main
    sparse_autoencoder = SAETrainingRunner(cfg).run()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 113, in run
    sae = self.run_trainer_with_interruption_handling(trainer)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 152, in run_trainer_with_interruption_handling
    sae = trainer.fit()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/sae_trainer.py", line 177, in fit
    self.activations_store.set_norm_scaling_factor_if_needed()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 422, in set_norm_scaling_factor_if_needed
    self.estimated_norm_scaling_factor = self.estimate_norm_scaling_factor()
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 449, in estimate_norm_scaling_factor
    acts = self.next_batch()[0]
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 785, in next_batch
    self._dataloader = self.get_data_loader()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 734, in get_data_loader
    self.get_buffer(self.half_buffer_size, raise_on_epoch_end=True),
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 688, in get_buffer
    refill_activations = self.get_activations(refill_batch_tokens)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 534, in get_activations
    layerwise_activations_cache = self.model.run_with_cache(
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py", line 694, in run_with_cache
    out, cache_dict = super().run_with_cache(
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformer_lens/hook_points.py", line 569, in run_with_cache
    model_out = self(*model_args, **model_kwargs)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py", line 583, in forward
    ) = self.input_to_embed(
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py", line 375, in input_to_embed
    if (
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py", line 279, in __len__
    return self._tokenizer.get_vocab_size(with_added_tokens=True)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 27, in interrupt_callback
    raise InterruptedException()
sae_lens.sae_training_runner.InterruptedException
Traceback (most recent call last):
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 782, in next_batch
    return next(self.dataloader)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 763, in _next_data
    index = self._next_index()  # may raise StopIteration
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 698, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/train_SAE.py", line 94, in <module>
    main()
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/train_SAE.py", line 89, in main
    sparse_autoencoder = SAETrainingRunner(cfg).run()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 113, in run
    sae = self.run_trainer_with_interruption_handling(trainer)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 152, in run_trainer_with_interruption_handling
    sae = trainer.fit()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/sae_trainer.py", line 177, in fit
    self.activations_store.set_norm_scaling_factor_if_needed()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 422, in set_norm_scaling_factor_if_needed
    self.estimated_norm_scaling_factor = self.estimate_norm_scaling_factor()
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 449, in estimate_norm_scaling_factor
    acts = self.next_batch()[0]
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 785, in next_batch
    self._dataloader = self.get_data_loader()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 734, in get_data_loader
    self.get_buffer(self.half_buffer_size, raise_on_epoch_end=True),
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 688, in get_buffer
    refill_activations = self.get_activations(refill_batch_tokens)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 534, in get_activations
    layerwise_activations_cache = self.model.run_with_cache(
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py", line 694, in run_with_cache
    out, cache_dict = super().run_with_cache(
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformer_lens/hook_points.py", line 569, in run_with_cache
    model_out = self(*model_args, **model_kwargs)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py", line 583, in forward
    ) = self.input_to_embed(
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py", line 375, in input_to_embed
    if (
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py", line 279, in __len__
    return self._tokenizer.get_vocab_size(with_added_tokens=True)
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 27, in interrupt_callback
    raise InterruptedException()
sae_lens.sae_training_runner.InterruptedException
