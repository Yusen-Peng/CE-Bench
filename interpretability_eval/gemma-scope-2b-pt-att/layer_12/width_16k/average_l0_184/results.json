{
    "sae_release": "gemma-scope-2b-pt-att",
    "sae_id": "layer_12/width_16k/average_l0_184",
    "contrastive_score_mean": 46.335827876612086,
    "independent_score_mean": 42.90635217096388,
    "interpretability_score_mean": 36.32011905158918,
    "total_rows": 500,
    "sae_config": {
        "architecture": "jumprelu",
        "d_in": 2048,
        "d_sae": 16384,
        "dtype": "torch.bfloat16",
        "device": "cuda",
        "model_name": "gemma-2-2b",
        "hook_name": "blocks.12.attn.hook_z",
        "hook_layer": 12,
        "hook_head_index": null,
        "activation_fn_str": "relu",
        "activation_fn_kwargs": {},
        "apply_b_dec_to_input": false,
        "finetuning_scaling_factor": false,
        "sae_lens_training_version": null,
        "prepend_bos": true,
        "dataset_path": "monology/pile-uncopyrighted",
        "dataset_trust_remote_code": true,
        "context_size": 1024,
        "normalize_activations": null,
        "neuronpedia_id": null,
        "model_from_pretrained_kwargs": {},
        "seqpos_slice": [
            null
        ]
    },
    "date": "2025-05-07 03:16:56"
}