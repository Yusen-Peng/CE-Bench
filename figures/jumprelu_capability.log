Loaded pretrained model meta-llama/Llama-3.2-1B into HookedTransformer
Tokenized prompt: ['<|begin_of_text|>', 'When', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' John', ' gave', ' the', ' bag', ' to']
Tokenized answer: [' Mary']
Performance on answer token:
Rank: 0        Logit: 24.70 Prob: 85.16% Token: | Mary|
Top 0th token. Logit: 24.70 Prob: 85.16% Token: | Mary|
Top 1th token. Logit: 21.91 Prob:  5.25% Token: | his|
Top 2th token. Logit: 21.22 Prob:  2.64% Token: | the|
Top 3th token. Logit: 19.79 Prob:  0.63% Token: | a|
Top 4th token. Logit: 18.91 Prob:  0.26% Token: | John|
Top 5th token. Logit: 18.76 Prob:  0.23% Token: | their|
Top 6th token. Logit: 18.56 Prob:  0.18% Token: | Mrs|
Top 7th token. Logit: 18.52 Prob:  0.18% Token: | her|
Top 8th token. Logit: 18.46 Prob:  0.17% Token: | Maria|
Top 9th token. Logit: 18.38 Prob:  0.15% Token: | me|
Ranks of the answer tokens: [(' Mary', 0)]
Tokenized prompt: ['<|begin_of_text|>', 'When', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' John', ' gave', ' the', ' bag', ' to']
Tokenized answer: [' Mary']
Padded sae_out from torch.Size([1, 14, 2048]) to torch.Size([1, 16, 2048])
Performance on answer token:
Rank: 84       Logit: 14.15 Prob:  0.07% Token: | Mary|
Top 0th token. Logit: 20.60 Prob: 42.42% Token: | the|
Top 1th token. Logit: 18.36 Prob:  4.51% Token: |,|
Top 2th token. Logit: 18.03 Prob:  3.24% Token: | him|
Top 3th token. Logit: 17.92 Prob:  2.91% Token: | her|
Top 4th token. Logit: 17.45 Prob:  1.81% Token: | them|
Top 5th token. Logit: 17.34 Prob:  1.64% Token: | his|
Top 6th token. Logit: 17.23 Prob:  1.47% Token: | me|
Top 7th token. Logit: 17.19 Prob:  1.40% Token: | you|
Top 8th token. Logit: 17.15 Prob:  1.35% Token: |.|
Top 9th token. Logit: 17.12 Prob:  1.31% Token: | a|
Ranks of the answer tokens: [(' Mary', 84)]
