Loaded pretrained model meta-llama/Llama-3.2-1B into HookedTransformer
Tokenized prompt: ['<|begin_of_text|>', 'When', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' John', ' gave', ' the', ' bag', ' to']
Tokenized answer: [' Mary']
Performance on answer token:
Rank: 0        Logit: 24.70 Prob: 85.16% Token: | Mary|
Top 0th token. Logit: 24.70 Prob: 85.16% Token: | Mary|
Top 1th token. Logit: 21.91 Prob:  5.25% Token: | his|
Top 2th token. Logit: 21.22 Prob:  2.64% Token: | the|
Top 3th token. Logit: 19.79 Prob:  0.63% Token: | a|
Top 4th token. Logit: 18.91 Prob:  0.26% Token: | John|
Top 5th token. Logit: 18.76 Prob:  0.23% Token: | their|
Top 6th token. Logit: 18.56 Prob:  0.18% Token: | Mrs|
Top 7th token. Logit: 18.52 Prob:  0.18% Token: | her|
Top 8th token. Logit: 18.46 Prob:  0.17% Token: | Maria|
Top 9th token. Logit: 18.38 Prob:  0.15% Token: | me|
Ranks of the answer tokens: [(' Mary', 0)]
Tokenized prompt: ['<|begin_of_text|>', 'When', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' John', ' gave', ' the', ' bag', ' to']
Tokenized answer: [' Mary']
Padded sae_out from torch.Size([1, 14, 2048]) to torch.Size([1, 16, 2048])
Performance on answer token:
Rank: 50       Logit: 14.52 Prob:  0.12% Token: | Mary|
Top 0th token. Logit: 20.24 Prob: 36.19% Token: | the|
Top 1th token. Logit: 18.23 Prob:  4.85% Token: | her|
Top 2th token. Logit: 18.02 Prob:  3.94% Token: |,|
Top 3th token. Logit: 17.90 Prob:  3.50% Token: | him|
Top 4th token. Logit: 17.49 Prob:  2.32% Token: | his|
Top 5th token. Logit: 17.21 Prob:  1.76% Token: | them|
Top 6th token. Logit: 17.20 Prob:  1.74% Token: | me|
Top 7th token. Logit: 17.05 Prob:  1.50% Token: |.|
Top 8th token. Logit: 16.99 Prob:  1.42% Token: | a|
Top 9th token. Logit: 16.93 Prob:  1.32% Token: | their|
Ranks of the answer tokens: [(' Mary', 50)]
