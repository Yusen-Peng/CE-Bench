Traceback (most recent call last):
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/yusenp/.conda/envs/kan_llama/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/cached_train_SAE.py", line 90, in <module>
    main()
  File "/data/yusenp/NLP/KAN-LLaMA/preliminary_exploration/cached_train_SAE.py", line 85, in main
    sparse_autoencoder = SAETrainingRunner(cfg).run()
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/sae_training_runner.py", line 68, in __init__
    self.activations_store = ActivationsStore.from_config(
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 123, in from_config
    return cls(
  File "/data/yusenp/NLP/KAN-LLaMA/sae_lens/training/activations_store.py", line 272, in __init__
    raise ValueError(
ValueError: Dataset must have a 'tokens', 'input_ids', 'text', or 'problem' column.
Using device: cuda
training with jumprelu architecture with 1000 steps
Loaded pretrained model meta-llama/Llama-3.2-1B into HookedTransformer
